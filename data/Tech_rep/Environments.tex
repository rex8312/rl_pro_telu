\section{Environments used for Evaluation}
The algorithms are evaluated on three different environments which all represent a balancing task in which the desired state is an unstable equilibrium. The considered experiments are \textit{Magnetic Levitation}, \textit{Ball Balancer} and \textit{Furuta Pendulum}. All environments are characterized by a state $s$. For each state $s$, the agent can choose an action and receives a reward from the environment. Since the algorithm can be implemented in a continuous environment, state and action space are continuous.
\subsection{Magnetic Levitation}
The experiments are ordered based on their complexity. For Magnetic Levitation, a ball is placed in the middle of a magnetic field which is generated by an electromagnet. By controlling the coil voltage, the direction and strength of the magnetic field can be regulated which applies a force onto the ball. The desired task is to minimize the deflection of the ball from its neutral position while using the least amount of current to fulfill the task. Therefore, the states are sufficiently described by a distance measure in the vertical direction and the current of the coil.
%TODO Explaining the reward function
\subsection{Furuta Pendulum}
The pendulum consists of two connected arms. The first one is attached to an motor at its end and can rotates around the vertical axis. The end of the first and second arm are aligned perpendicularly. The task is to balance the second arm upright by choosing the right momentum. The system is fully described by the angles of the arm and pole as well as the angular velocity of the arm. For numerical reasons, the sines and cosines of the respective angles are stored resulting in 6 observed states.	
\subsection{Ball Balancer}
observation space is 8 
action space is 2